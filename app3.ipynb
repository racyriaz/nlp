{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "source": [
    "## Loading the Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 121175 entries, 0 to 121174\nData columns (total 9 columns):\n #   Column       Non-Null Count   Dtype \n---  ------       --------------   ----- \n 0   uuid         121175 non-null  object\n 1   title        121173 non-null  object\n 2   image        121175 non-null  object\n 3   description  119832 non-null  object\n 4   language     121175 non-null  object\n 5   categories   121175 non-null  object\n 6   website      120005 non-null  object\n 7   author       118678 non-null  object\n 8   itunes_id    121175 non-null  int64 \ndtypes: int64(1), object(8)\nmemory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('./podcasts.csv')\n",
    "\n",
    "# information about the dataset\n",
    "raw_data.info()"
   ]
  },
  {
   "source": [
    "## Selecting only the title, paper text column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_data[['title','description']].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "title          0.0\n",
       "description    0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# checking for null values\n",
    "df.isnull().sum()/df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the missing values \n",
    "df.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "title          0\n",
       "description    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "source": [
    "# Removing the STOPWORDS after tokenization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# IMPORTING THE STOPWORDS FOR ENGLISH LANGUAGE\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = list(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords(x):\n",
    "    words = word_tokenize(x)\n",
    "    token = []\n",
    "    for i in words:\n",
    "        if i not in stop_words:\n",
    "            token.append(i)\n",
    "    return token\n",
    "\n",
    "df['f_tokens']=df.description.apply(filter_stopwords)"
   ]
  },
  {
   "source": [
    "# Lemmatization tokens in base form with WORDNET Nltk tool"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['title', 'description', 'f_tokens'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer =  WordNetLemmatizer()\n",
    "\n",
    "def lema(x):\n",
    "    lemas = []\n",
    "    for i in x:\n",
    "        lemas.append(lemmatizer.lemmatize(i))\n",
    "    return lemas\n",
    "df['lemma'] = df.f_tokens.apply(lema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               title  \\\n",
       "0    Ecommerce Conversations, by Practical Ecommerce   \n",
       "1                             Eat Sleep Code Podcast   \n",
       "2                                    SoundtrackAlley   \n",
       "3                               The Tech M&A Podcast   \n",
       "4  The Tech Informist - For fans of Apple, Google...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Listen in as the Practical Ecommerce editorial...   \n",
       "1  On the show we’ll be talking to passionate peo...   \n",
       "2  A podcast about soundtracks and movies from my...   \n",
       "3  The Tech M&A Podcast pulls from the best of th...   \n",
       "4  The tech news show with two guys shooting the ...   \n",
       "\n",
       "                                            f_tokens  \\\n",
       "0  [Listen, Practical, Ecommerce, editorial, staf...   \n",
       "1  [On, show, ’, talking, passionate, people, wid...   \n",
       "2  [A, podcast, soundtracks, movies, childhood, b...   \n",
       "3  [The, Tech, M, &, A, Podcast, pulls, best, Tec...   \n",
       "4  [The, tech, news, show, two, guys, shooting, b...   \n",
       "\n",
       "                                               lemma  \n",
       "0  [Listen, Practical, Ecommerce, editorial, staf...  \n",
       "1  [On, show, ’, talking, passionate, people, wid...  \n",
       "2  [A, podcast, soundtrack, movie, childhood, bey...  \n",
       "3  [The, Tech, M, &, A, Podcast, pull, best, Tech...  \n",
       "4  [The, tech, news, show, two, guy, shooting, br...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>description</th>\n      <th>f_tokens</th>\n      <th>lemma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ecommerce Conversations, by Practical Ecommerce</td>\n      <td>Listen in as the Practical Ecommerce editorial...</td>\n      <td>[Listen, Practical, Ecommerce, editorial, staf...</td>\n      <td>[Listen, Practical, Ecommerce, editorial, staf...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Eat Sleep Code Podcast</td>\n      <td>On the show we’ll be talking to passionate peo...</td>\n      <td>[On, show, ’, talking, passionate, people, wid...</td>\n      <td>[On, show, ’, talking, passionate, people, wid...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SoundtrackAlley</td>\n      <td>A podcast about soundtracks and movies from my...</td>\n      <td>[A, podcast, soundtracks, movies, childhood, b...</td>\n      <td>[A, podcast, soundtrack, movie, childhood, bey...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Tech M&amp;A Podcast</td>\n      <td>The Tech M&amp;A Podcast pulls from the best of th...</td>\n      <td>[The, Tech, M, &amp;, A, Podcast, pulls, best, Tec...</td>\n      <td>[The, Tech, M, &amp;, A, Podcast, pull, best, Tech...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Tech Informist - For fans of Apple, Google...</td>\n      <td>The tech news show with two guys shooting the ...</td>\n      <td>[The, tech, news, show, two, guys, shooting, b...</td>\n      <td>[The, tech, news, show, two, guy, shooting, br...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "On the show we’ll be talking to passionate people about a wide range of developer related topics.\n\nPart of the Telerik Developer Network , Eat Sleep Code is the Official Telerik Podcast. At Telerik we believe in giving back to the developer community and we do this by writing, speaking and staying in touch with the software development community.\n\n\n\n\n\n['On', 'show', '’', 'talking', 'passionate', 'people', 'wide', 'range', 'developer', 'related', 'topic', '.', 'Part', 'Telerik', 'Developer', 'Network', ',', 'Eat', 'Sleep', 'Code', 'Official', 'Telerik', 'Podcast', '.', 'At', 'Telerik', 'believe', 'giving', 'back', 'developer', 'community', 'writing', ',', 'speaking', 'staying', 'touch', 'software', 'development', 'community', '.']\n"
     ]
    }
   ],
   "source": [
    "print(df.description.iloc[1])\n",
    "print(\"\\n\")\n",
    "print(df.lemma.iloc[1])"
   ]
  },
  {
   "source": [
    "# Lemmatizing with SpaCy tool"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load(disable=['parser','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_lema(x):\n",
    "    lemas = []\n",
    "    for i in x:\n",
    "        lemas.append(nlp(i))\n",
    "    return lemas\n",
    "\n",
    "df['spacy'] = df.f_tokens.apply(spacy_lema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "On the show we’ll be talking to passionate people about a wide range of developer related topics.\n\nPart of the Telerik Developer Network , Eat Sleep Code is the Official Telerik Podcast. At Telerik we believe in giving back to the developer community and we do this by writing, speaking and staying in touch with the software development community.\n\n\n\n\n\n['On', 'show', '’', 'talking', 'passionate', 'people', 'wide', 'range', 'developer', 'related', 'topic', '.', 'Part', 'Telerik', 'Developer', 'Network', ',', 'Eat', 'Sleep', 'Code', 'Official', 'Telerik', 'Podcast', '.', 'At', 'Telerik', 'believe', 'giving', 'back', 'developer', 'community', 'writing', ',', 'speaking', 'staying', 'touch', 'software', 'development', 'community', '.']\n\n\n[On, show, ’, talking, passionate, people, wide, range, developer, related, topics, ., Part, Telerik, Developer, Network, ,, Eat, Sleep, Code, Official, Telerik, Podcast, ., At, Telerik, believe, giving, back, developer, community, writing, ,, speaking, staying, touch, software, development, community, .]\n"
     ]
    }
   ],
   "source": [
    "print(df.description.iloc[1])\n",
    "print(\"\\n\")\n",
    "print(df.lemma.iloc[1])\n",
    "print(\"\\n\")\n",
    "print(df.spacy.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}